{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelbuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates the set up of a model to investigate NbS for coastal flooding. The example here presents a usecase for the Wash (United Kingdom) and combines input data from multiple sources. The model is set up using the HydroMT_sfincs python package. The usecase here requires a selection of its functionalities. If you want to learn more about building sfincs models this way, visit [HydroMT_sfincs - Modelbuilder example from script](https://github.com/Deltares/hydromt_sfincs/blob/main/examples/build_from_script.ipynb).\n",
    "\n",
    "This modelbuilder combines many other Python packages. HydroMT_sfincs is used for the set up of the sfincs model, matplotlib for visualization, (rio)xarray to process netcdf files and geopandas to process geospatial data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and user variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from os.path import join\n",
    "import geopandas as gpd\n",
    "import hydromt\n",
    "from hydromt_sfincs import SfincsModel\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main directory and data library\n",
    "# This is the directory where the data library is stored\n",
    "data_libs = './input_dir/edito_sfincs_data.yml'\n",
    "input_dir = './input_dir' \n",
    "main_dir = './wash_uk_example' \n",
    "\n",
    "# This is the directory where the model will be saved\n",
    "sim_dir   = join(main_dir, 'sims')\n",
    "if not os.path.exists(sim_dir):\n",
    "    os.makedirs(sim_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input files\n",
    "fn_domain       =  join(input_dir, 'domain.gpkg')\n",
    "fn_domain_lines =  join(input_dir, 'domain_lines.gpkg')\n",
    "fn_topo         = join(input_dir, 'delta_dtm_gebco_ref_msl.tif')\n",
    "fn_veg          =  join(input_dir, 'da_veg.tif')\n",
    "fn_storm_wl     =  join(input_dir, 'wl_ts.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid resolution\n",
    "grid_resolution     = 50     # meters\n",
    "\n",
    "# Define the roughness parameters\n",
    "manning_saltmarshes = 0.08   # 0.07 Rezaie et al., 2020\n",
    "manning_mangroves   = 0.15   # Zhang et al., 2012\n",
    "manning_land        = 0.04   # default\n",
    "manning_sea         = 0.02   # default\n",
    "\n",
    "# Define waterlevel offset\n",
    "slr_mean = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model observation points\n",
    "obs_names             = ['veg1','veg2']\n",
    "obs_pnts              = [Point(303082.833,5864791.153), \n",
    "                         Point(315739.571,5854677.962)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model dir already exists and files might be overwritten: p:\\11209182-edito\\06-Models\\SFINCS_nbs_example\\03_wash_uk_example\\sims_test\\sim_veg\\gis.\n"
     ]
    }
   ],
   "source": [
    "# Initialize hydromt DataCatalog\n",
    "data_cat  = hydromt.DataCatalog(data_libs = data_libs)\n",
    "\n",
    "# Initialize SFINCS model\n",
    "mod = SfincsModel(root  = sim_dir+ '/sim_veg',  mode = 'w+', data_libs = data_libs)\n",
    "gdf_domain       = gpd.read_file(fn_domain)\n",
    "gdf_domain_lines = gpd.read_file(fn_domain_lines) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid & Topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid from polygon in GeoDataFrame   \n",
    "mod.setup_grid_from_region(region = {'geom':gdf_domain}, res = grid_resolution, rotated = True)\n",
    "mod.config\n",
    "\n",
    "# Define topography and vegetation datasets\n",
    "da_topo   = data_cat.get_rasterdataset(fn_topo)\n",
    "da_veg    = data_cat.get_rasterdataset(fn_veg)\n",
    "\n",
    "# Assign topography to the model\n",
    "datasets_dep  = [{\"elevtn\":da_topo}]\n",
    "da_dep        = mod.setup_dep(datasets_dep=datasets_dep, buffer_cells= 1) # \n",
    "\n",
    "# set mask based on elevation (areas in km2)\n",
    "mod.setup_mask_active(mask = gdf_domain , zmax = 10, drop_area = 10, fill_area = 100, reset_mask = True) \n",
    "mod.set_config(\"stopdepth\", '250.0')\n",
    "   \n",
    "# Assign observation points to the model\n",
    "gdf_obs               = gpd.GeoDataFrame({'names': obs_names}, geometry = obs_pnts, crs = mod.crs).set_index('names')\n",
    "mod.setup_observation_points(gdf_obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model boundaries\n",
    "gdf_all_lines = gdf_domain_lines.loc[(gdf_domain_lines['bnd']==1)] \n",
    "if len(gdf_all_lines) > 0:\n",
    "    gdf_all_lines = gdf_all_lines.loc[gdf_all_lines['geometry'] != None]\n",
    "    gdf_all_lines.geometry = gdf_all_lines['geometry'].buffer(0.0075)\n",
    "mod.setup_mask_bounds(btype = \"waterlevel\", include_mask = gdf_all_lines  , reset_bounds=True, zmax = 1) # here we mask the wl for all bnd points     \n",
    "\n",
    "#update times, in line with wl forcing (times should be updated afeter setup_mask_bounds)\n",
    "mod.set_config(\"tref\"  , \"20000101 000000\")\n",
    "mod.set_config(\"tstart\", \"20000101 000000\")\n",
    "mod.set_config(\"tstop\" , \"20000106 000000\")\n",
    "mod.set_config(\"dtout\",  \"600\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mod.setup_waterlevel_forcing(geodataset = fn_storm_wl, offset=slr_mean , buffer = 15000)\n",
    "df_ts = mod.forcing['bzs'].to_dataframe()\n",
    "df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[0]\n",
    "df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[-1]\n",
    "t_start = str(df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[0][0]).replace('-','').replace(':','')\n",
    "t_end   = str(df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[-1][0]).replace('-','').replace(':','')\n",
    "\n",
    "#update times, in line with wl forcing\n",
    "mod.set_config(\"tref\"  , \"20000101 000000\")\n",
    "mod.set_config(\"tstart\", t_start)\n",
    "mod.set_config(\"tstop\" , t_end)\n",
    "mod.set_config(\"dtout\",  \"600\")\n",
    "mod.set_config(\"dtmaxout\",\"9999999\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add spatially varying roughness data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate the influence of different roughness for land, sea, and vegetation on flow this is added to the model based on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set increased Manning values for vegetation cover\n",
    "mapping = {1:manning_saltmarshes, 2:manning_mangroves}\n",
    "manning_veg_map = da_veg.copy()\n",
    "for old_value, new_value in mapping.items():\n",
    "    manning_veg_map = manning_veg_map.where(manning_veg_map != old_value, new_value)\n",
    "  \n",
    "datasets_rgh = [{'manning':manning_veg_map}]\n",
    "mod.setup_manning_roughness(\n",
    "           datasets_rgh=datasets_rgh,\n",
    "           manning_land= manning_land,\n",
    "           manning_sea= manning_sea,\n",
    "           rgh_lev_land=0,  # the minimum elevation of the land\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the model with vegation to files\n",
    "mod.write()\n",
    "\n",
    "# create a copy for the model without vegetation for comparison\n",
    "shutil.copytree(sim_dir + '/sim_veg', sim_dir + '/sim_noveg', dirs_exist_ok = True)\n",
    "os.remove(sim_dir + '/sim_noveg/hydromt_data.yml')\n",
    "\n",
    "# load the model and change manning file \n",
    "mod_noveg = SfincsModel(root  = sim_dir + '/sim_noveg',  mode = 'r+', data_libs = data_libs)\n",
    "mod_noveg.config\n",
    "\n",
    "mod_noveg.setup_manning_roughness(\n",
    "              manning_land = manning_land,\n",
    "              manning_sea  = manning_sea,\n",
    "              rgh_lev_land = 0)  # the minimum elevation of the land\n",
    "\n",
    "mod_noveg.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model to EDITO storage [no vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the generated model to youe s3 bucket in \"SFINCS_INPUT\"\n",
    "from upload_model import upload_model_to_s3_bucket\n",
    "upload_model_to_s3_bucket(join(sim_dir, 'sim_noveg'), 'SFINCS_INPUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SFINCS simulation [no vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from launch_sfincs_process import launch_process_in_browser\n",
    "launch_process_in_browser(\n",
    "        cpu_request=\"1800m\",\n",
    "    memory_request=\"5Gi\",\n",
    "    cpu_limit=\"6400m\",\n",
    "    memory_limit=\"28Gi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import simulation output [no vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_from_s3 import download_nc_files_from_s3\n",
    "\n",
    "# import simulation output\n",
    "download_nc_files_from_s3(\n",
    "    files_to_download=['sfincs_map.nc', 'sfincs_his.nc'],\n",
    "    s3_subfolder='SFINCS_OUTPUT',\n",
    "    local_output_dir=join(sim_dir, 'sim_noveg')  # or 'sim_veg'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model to EDITO storage [vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the generated model to youe s3 bucket in \"SFINCS_INPUT\"\n",
    "from upload_model import upload_model_to_s3_bucket\n",
    "upload_model_to_s3_bucket(join(sim_dir, 'sim_veg'), 'SFINCS_INPUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SFINCS simulation [vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from launch_sfincs_process import launch_process_in_browser\n",
    "launch_process_in_browser(\n",
    "        cpu_request=\"1800m\",\n",
    "    memory_request=\"5Gi\",\n",
    "    cpu_limit=\"6400m\",\n",
    "    memory_limit=\"28Gi\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import simulation output [vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_from_s3 import download_nc_files_from_s3\n",
    "\n",
    "# import simulation output\n",
    "download_nc_files_from_s3(\n",
    "    files_to_download=['sfincs_map.nc', 'sfincs_his.nc'],\n",
    "    s3_subfolder='SFINCS_OUTPUT',\n",
    "    local_output_dir=join(sim_dir, 'sim_veg')  # or 'sim_veg'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sfincs_mod_read_h(dir_sfincs_model, hmin=0.05, apply_hmin = False):\n",
    "    \n",
    "    mod = SfincsModel(dir_sfincs_model, mode = \"r\")\n",
    "    \n",
    "    mod.read_results(chunksize = 10)\n",
    "    # the following variables have been found\n",
    "    list(mod.results.keys())\n",
    "    da_h = mod.results[\"h\"]\n",
    "    if apply_hmin == True:\n",
    "        da_h = da_h.where(da_h > hmin)\n",
    "    da_h.attrs.update(long_name=\"flood depth\", unit=\"m\")\n",
    "    \n",
    "    return da_h\n",
    "\n",
    "def load_hmax_noveg(dir_sfincs_model_noveg, dir_sfincs_model_veg, hmin = 0.05):\n",
    "    # load model\n",
    "    da_h_noveg = sfincs_mod_read_h(dir_sfincs_model_noveg, hmin)\n",
    "    da_h_veg   = sfincs_mod_read_h(dir_sfincs_model_veg, hmin)\n",
    "    dif = da_h_veg - da_h_noveg # postive values are increase, negative equals reduction\n",
    "    \n",
    "    # veg extent\n",
    "    mod = SfincsModel(dir_sfincs_model_noveg, mode = \"r\")\n",
    "\n",
    "    return dif, da_h_noveg, mod\n",
    "\n",
    "def load_h_his(dir_sfincs_model_noveg, dir_sfincs_model_veg,\n",
    "               obs = ''):\n",
    "    mod_noveg = SfincsModel(dir_sfincs_model_noveg, mode = \"r\")\n",
    "    mod_veg   = SfincsModel(dir_sfincs_model_veg, mode = \"r\") \n",
    "    \n",
    "    if len(obs) ==0:\n",
    "        station_id = 0 \n",
    "        \n",
    "    h_noveg = mod_noveg.results['point_h'].isel(stations = station_id)\n",
    "    h_veg   = mod_veg.results['point_h'].isel(stations = station_id)\n",
    "\n",
    "    return h_noveg, h_veg\n",
    "\n",
    "\n",
    "def numfmt(x,pos):\n",
    "    s = '{}'.format(x/1000.0)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "def make_movie_from_pngs(folder, fps = 4):\n",
    "\n",
    "    \n",
    "    def update(frame):\n",
    "        img.set_data(images[frame])\n",
    "        return img\n",
    "\n",
    "\n",
    "    #list files in folder\n",
    "    png_files = [ f.path for f in os.scandir(folder) if f.is_file() ]\n",
    "    \n",
    "    images = [Image.open(path) for path in png_files]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize = (8,4), dpi = 300)\n",
    "    ax.set_axis_off()  # Turn off axis for cleaner animation\n",
    "    img = ax.imshow(images[0])  # Display the first image\n",
    "    \n",
    "    \n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(images), interval=200, blit=False)\n",
    "    # save to file\n",
    "    ani.save(join(folder,'output_movie.mp4'), writer='ffmpeg', fps = fps, dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_sfincs_model_noveg =  join(sim_dir, 'sim_noveg')\n",
    "dir_sfincs_model_veg =  join(sim_dir, 'sim_veg')\n",
    "\n",
    "out_dir = join(sim_dir, 'figs/dif')\n",
    "out_dir_his = join(sim_dir, 'figs')\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "hmin     = 0.05\n",
    "fs_ticks = 9\n",
    "plot_veg = False\n",
    "EO       = True\n",
    "zoomlevel = 10\n",
    "da_h_dif, da_h_noveg, mod = load_hmax_noveg(dir_sfincs_model_noveg, dir_sfincs_model_veg, hmin)\n",
    "his_noveg, his_veg        = load_h_his(dir_sfincs_model_noveg, dir_sfincs_model_veg)\n",
    "\n",
    "gswo       = data_cat.get_rasterdataset(join(input_dir, 'gswo.tif'))\n",
    "gswo_mask  = gswo.raster.reproject_like(mod.grid, method=\"max\") <= 5\n",
    "\n",
    "da_h_noveg = da_h_noveg.where(gswo_mask).where(da_h_noveg > hmin)\n",
    "\n",
    "# apply min dif filter\n",
    "da_h_dif = da_h_dif.where(abs(da_h_dif)>hmin/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.io.img_tiles import GoogleTiles\n",
    "import datetime\n",
    "import matplotlib.ticker as tkr\n",
    "from pylab import plot, show, savefig, xlim, figure, ylim, legend, boxplot, setp, axes\n",
    "import gc\n",
    "\n",
    "utm_zone = da_h_dif.raster.crs.to_wkt().split(\"UTM zone \")[1][:3]\n",
    "extent = np.array(da_h_dif.raster.box.buffer(1e2).total_bounds)[[0, 2, 1, 3]]\n",
    "\n",
    "for t in da_h_dif.time[:]:\n",
    "\n",
    "    crs = ccrs.UTM(int(utm_zone[:2]))\n",
    "    fig, axs = plt.subplots(1,2, subplot_kw={'projection': crs}, figsize = (8,4))\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.set_extent(extent, crs = crs)\n",
    "        tiler = GoogleTiles(style = 'satellite')\n",
    "        ax.add_image(tiler, int(zoomlevel))\n",
    "\n",
    "    ax1 = axs[0]; ax2 = axs[1]\n",
    "    \n",
    "    # plot difference veg no veg\n",
    "    cbar_kwargs = {\"shrink\": 0.8, \"orientation\":'horizontal', \"label\":'Flood depth [m +MSL]'}\n",
    "    da_plot = da_h_noveg.sel(time = t)\n",
    "    cax_fld = da_plot.plot(\n",
    "        x=\"xc\", y=\"yc\",\n",
    "        ax=ax1,\n",
    "        vmin=0, vmax=2,\n",
    "        cmap=plt.cm.Spectral,\n",
    "        alpha = 0.8,\n",
    "        cbar_kwargs = cbar_kwargs)\n",
    "\n",
    "    # plot difference veg no veg\n",
    "    cbar_kwargs = {\"shrink\": 0.8, \"orientation\":'horizontal', \"label\":'$\\Delta$ Flood depth [m]'}\n",
    "    da_plot = da_h_dif.sel(time = t)\n",
    "    cax_fld = da_plot.plot(\n",
    "        x=\"xc\", y=\"yc\",\n",
    "        ax=ax2,\n",
    "        vmin=-0.5, vmax=0.5,\n",
    "        cmap=plt.cm.bwr,\n",
    "        alpha = 0.8,\n",
    "        cbar_kwargs = cbar_kwargs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax1.scatter(his_noveg.station_x.values, his_noveg.station_y.values, color = 'white', s = 5, marker = '*', zorder = 5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    datesuffix       = str(np.datetime64(t.time.values,'m')).replace('-','');\n",
    "    datesuffix_title = datetime.datetime.strptime(datesuffix, \"%Y%m%dT%H:%M\").strftime(\"%d-%m-%Y %H:%M\")\n",
    "    print(datesuffix)\n",
    "    ax = [ax1,ax2]\n",
    "    utm_suffix = da_h_dif.raster.crs.name.split('/')[1]\n",
    "    for i in np.arange(2):\n",
    "    # update axis labels\n",
    "        ax[i].xaxis.set_visible(True)\n",
    "        ax[i].yaxis.set_visible(True)\n",
    "        ax[i].set_xlabel('X-coordinate [km] ' + utm_suffix, fontsize = fs_ticks)\n",
    "        if i == 0: # ylabel on\n",
    "            ax[i].set_ylabel('Y-coordinate [km] ' + utm_suffix, fontsize = fs_ticks)\n",
    "        else:\n",
    "            ax[i].set_ylabel('')\n",
    "        yfmt = tkr.FuncFormatter(numfmt)\n",
    "        ax[i].yaxis.set_major_formatter(yfmt); ax[i].xaxis.set_major_formatter(yfmt)\n",
    "        ax[i].tick_params(axis=\"both\", direction='out', length=3, labelsize = fs_ticks); \n",
    "\n",
    "        ax[i].set_title(datesuffix_title)\n",
    "\n",
    "\n",
    "    savefig(join(out_dir, datesuffix.replace(':','_') + '_' + 'h_dif.png'), dpi = 300,bbox_inches='tight')\n",
    "\n",
    "    fig.clf()\n",
    "    plt.close(fig)\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make movie\n",
    "from PIL import Image\n",
    "from matplotlib import animation\n",
    "make_movie_from_pngs(out_dir, fps = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot forcing\n",
    "import xarray as xr\n",
    "da_wl = xr.open_dataset(join(input_dir,'wl_ts.nc'))\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "idxs = da_wl.stations.values\n",
    "for idx in idxs:\n",
    "    da_wl.sel(stations = idx)['waterlevel'].plot(label = idx+1)\n",
    "\n",
    "ax.set_title('')\n",
    "ax.set_ylabel('Water level [m +MSL]')\n",
    "ax.axhline(y = 0, color = 'darkgrey', ls = '--')\n",
    "ax.legend(ncol = 4)\n",
    "\n",
    "savefig(join(out_dir_his, 'forcing_wl.png'), dpi = 300,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time series\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, axs = plt.subplots(2,1)\n",
    "\n",
    "ax = axs[0]\n",
    "t = his_noveg['time']\n",
    "z = his_noveg.values\n",
    "z_veg = his_veg.values\n",
    "elapsed_hours = (t.values - t.values[0]) / np.timedelta64(1, 'h')\n",
    "\n",
    "\n",
    "ax.plot(elapsed_hours,z, color = 'navy', label = 'noveg')\n",
    "ax.plot(elapsed_hours, z_veg, color = 'limegreen', label = 'veg')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel('Water depth [m]')\n",
    "ax.legend()\n",
    "\n",
    "ax = axs[1]\n",
    "delta = z_veg -z\n",
    "ax.plot(elapsed_hours, delta)\n",
    "\n",
    "ax.set_xlabel('Hours since start')\n",
    "ax.set_ylabel('Water depth \\ndifference [m]')\n",
    "\n",
    "ax.set_ylim(-0.5,0.5)\n",
    "ax.text(0.55, 0.2,'reduction due to veg', transform = ax.transAxes)\n",
    "ax.text(0.55, 0.7,'increase due to veg', transform = ax.transAxes)\n",
    "ax.axhline(0,ls = '--', color = 'black', lw = 0.5)\n",
    "\n",
    "\n",
    "savefig(join(out_dir_his, 'obs_dif.png'), dpi = 300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload plots to EDITO storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from upload_model import upload_model_to_s3_bucket\n",
    "upload_model_to_s3_bucket(join(sim_dir, 'figs'), 'SFINCS_OUTPUT')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfincs_mangroves",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

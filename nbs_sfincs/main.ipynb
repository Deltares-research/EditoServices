{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nature Based Solution What-if scenario with SFINCS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook illustrates the set up, execution, and visualization of an inundation model to investigate Nature based Solutions for coastal flooding. The example here presents a usecase for the Wash (United Kingdom) and combines input data from multiple sources.**\n",
    "\n",
    "_Technical information: \n",
    "The model is set up using the HydroMT_sfincs python package. The usecase here requires a selection of its functionalities. If you want to learn more about building sfincs models this way, visit [HydroMT_sfincs - Modelbuilder example from script](https://github.com/Deltares/hydromt_sfincs/blob/main/examples/build_from_script.ipynb)._\n",
    "\n",
    "_This modelbuilder combines many other Python packages. HydroMT_sfincs is used for the set up of the sfincs model, matplotlib for visualization, (rio)xarray to process netcdf files and geopandas to process geospatial data._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Input\n",
    "\n",
    "**_Users can change the grid resolution, roughness parameters and simulate sea level rise what-if scenarios._**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid resolution\n",
    "grid_resolution     = 50     # meters\n",
    "\n",
    "# Define the roughness parameters\n",
    "manning_saltmarshes = 0.08   # 0.07 Rezaie et al., 2020\n",
    "manning_mangroves   = 0.15   # Zhang et al., 2012\n",
    "manning_land        = 0.04   # default\n",
    "manning_sea         = 0.02   # default\n",
    "\n",
    "# Define waterlevel offset\n",
    "slr_mean = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to EDITO\n",
    "from edito_process_api import set_edito_token\n",
    "tok = set_edito_token()   # prompts username/password, sets EDITO_ACCESS_TOKEN\n",
    "print(\"✅ EDITO token set | len:\", len(tok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "/* JupyterLab: hide inputs of CODE cells only (keep Markdown visible) */\n",
    ".jp-Notebook .jp-CodeCell .jp-InputArea { display: none !important; }\n",
    ".jp-Notebook .jp-CodeCell .jp-InputPrompt { display: none !important; }\n",
    "\n",
    "/* Classic Notebook: hide inputs of CODE cells only */\n",
    "div.code_cell > div.input { display: none !important; }\n",
    "div.code_cell .prompt { display: none !important; }\n",
    "</style>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "from os.path import join\n",
    "import geopandas as gpd\n",
    "import hydromt\n",
    "from hydromt_sfincs import SfincsModel\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main directory and data library\n",
    "# This is the directory where the data library is stored\n",
    "data_libs = './input_dir/edito_sfincs_data.yml'\n",
    "input_dir = './input_dir' \n",
    "main_dir = './wash_uk_example' \n",
    "\n",
    "# This is the directory where the model will be saved\n",
    "sim_dir   = join(main_dir, 'sims')\n",
    "if not os.path.exists(sim_dir):\n",
    "    os.makedirs(sim_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input files\n",
    "fn_domain       =  join(input_dir, 'domain.gpkg')\n",
    "fn_domain_lines =  join(input_dir, 'domain_lines.gpkg')\n",
    "fn_topo         = join(input_dir, 'delta_dtm_gebco_ref_msl.tif')\n",
    "fn_veg          =  join(input_dir, 'da_veg.tif')\n",
    "fn_storm_wl     =  join(input_dir, 'wl_ts.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model observation points\n",
    "obs_names             = ['veg1','veg2']\n",
    "obs_pnts              = [Point(303082.833,5864791.153), \n",
    "                         Point(315739.571,5854677.962)]\n",
    "print(\"✅ Input files defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize hydromt DataCatalog\n",
    "data_cat  = hydromt.DataCatalog(data_libs = data_libs)\n",
    "\n",
    "# Initialize SFINCS model\n",
    "mod = SfincsModel(root  = sim_dir+ '/sim_veg',  mode = 'w+', data_libs = data_libs)\n",
    "gdf_domain       = gpd.read_file(fn_domain)\n",
    "gdf_domain_lines = gpd.read_file(fn_domain_lines) \n",
    "print(\"✅ SFINCS model initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid & Topography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup grid from polygon in GeoDataFrame   \n",
    "mod.setup_grid_from_region(region = {'geom':gdf_domain}, res = grid_resolution, rotated = True)\n",
    "mod.config\n",
    "\n",
    "# Define topography and vegetation datasets\n",
    "da_topo   = data_cat.get_rasterdataset(fn_topo)\n",
    "da_veg    = data_cat.get_rasterdataset(fn_veg)\n",
    "\n",
    "# Assign topography to the model\n",
    "datasets_dep  = [{\"elevtn\":da_topo}]\n",
    "da_dep        = mod.setup_dep(datasets_dep=datasets_dep, buffer_cells= 1) # \n",
    "\n",
    "# set mask based on elevation (areas in km2)\n",
    "mod.setup_mask_active(mask = gdf_domain , zmax = 10, drop_area = 10, fill_area = 100, reset_mask = True) \n",
    "mod.set_config(\"stopdepth\", '250.0')\n",
    "   \n",
    "# Assign observation points to the model\n",
    "gdf_obs               = gpd.GeoDataFrame({'names': obs_names}, geometry = obs_pnts, crs = mod.crs).set_index('names')\n",
    "mod.setup_observation_points(gdf_obs)\n",
    "print(\"✅ Grid and topography defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boundary Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model boundaries\n",
    "gdf_all_lines = gdf_domain_lines.loc[(gdf_domain_lines['bnd']==1)] \n",
    "if len(gdf_all_lines) > 0:\n",
    "    gdf_all_lines = gdf_all_lines.loc[gdf_all_lines['geometry'] != None]\n",
    "    gdf_all_lines.geometry = gdf_all_lines['geometry'].buffer(0.0075)\n",
    "mod.setup_mask_bounds(btype = \"waterlevel\", include_mask = gdf_all_lines  , reset_bounds=True, zmax = 1) # here we mask the wl for all bnd points     \n",
    "\n",
    "#update times, in line with wl forcing (times should be updated afeter setup_mask_bounds)\n",
    "mod.set_config(\"tref\"  , \"20000101 000000\")\n",
    "mod.set_config(\"tstart\", \"20000101 000000\")\n",
    "mod.set_config(\"tstop\" , \"20000106 000000\")\n",
    "mod.set_config(\"dtout\",  \"600\")\n",
    "print(\"✅ Boundary conditions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mod.setup_waterlevel_forcing(geodataset = fn_storm_wl, offset=slr_mean , buffer = 15000)\n",
    "df_ts = mod.forcing['bzs'].to_dataframe()\n",
    "df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[0]\n",
    "df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[-1]\n",
    "t_start = str(df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[0][0]).replace('-','').replace(':','')\n",
    "t_end   = str(df_ts.index[~df_ts.isnull().any(axis=1)].tolist()[-1][0]).replace('-','').replace(':','')\n",
    "\n",
    "#update times, in line with wl forcing\n",
    "mod.set_config(\"tref\"  , \"20000101 000000\")\n",
    "mod.set_config(\"tstart\", t_start)\n",
    "mod.set_config(\"tstop\" , t_end)\n",
    "mod.set_config(\"dtout\",  \"600\")\n",
    "mod.set_config(\"dtmaxout\",\"9999999\")\n",
    "print(\"✅ Forcing defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add spatially varying roughness data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To incorporate the influence of different roughness for land, sea, and vegetation on flow this is added to the model based on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set increased Manning values for vegetation cover\n",
    "mapping = {1:manning_saltmarshes, 2:manning_mangroves}\n",
    "manning_veg_map = da_veg.copy()\n",
    "for old_value, new_value in mapping.items():\n",
    "    manning_veg_map = manning_veg_map.where(manning_veg_map != old_value, new_value)\n",
    "  \n",
    "datasets_rgh = [{'manning':manning_veg_map}]\n",
    "mod.setup_manning_roughness(\n",
    "           datasets_rgh=datasets_rgh,\n",
    "           manning_land= manning_land,\n",
    "           manning_sea= manning_sea,\n",
    "           rgh_lev_land=0,  # the minimum elevation of the land\n",
    "       )\n",
    "print(\"✅ Spatially varying roughness data defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the model with vegation to files\n",
    "mod.write()\n",
    "\n",
    "# create a copy for the model without vegetation for comparison\n",
    "shutil.copytree(sim_dir + '/sim_veg', sim_dir + '/sim_noveg', dirs_exist_ok = True)\n",
    "os.remove(sim_dir + '/sim_noveg/hydromt_data.yml')\n",
    "\n",
    "# load the model and change manning file \n",
    "mod_noveg = SfincsModel(root  = sim_dir + '/sim_noveg',  mode = 'r+', data_libs = data_libs)\n",
    "mod_noveg.config\n",
    "\n",
    "mod_noveg.setup_manning_roughness(\n",
    "              manning_land = manning_land,\n",
    "              manning_sea  = manning_sea,\n",
    "              rgh_lev_land = 0)  # the minimum elevation of the land\n",
    "\n",
    "mod_noveg.write()\n",
    "print(\"✅ Model configurations written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model to EDITO storage [no vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the generated model to youe s3 bucket in \"SFINCS_INPUT\"\n",
    "from upload_model import upload_model_to_s3_bucket\n",
    "upload_model_to_s3_bucket(join(sim_dir, 'sim_noveg'), 'SFINCS_INPUT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SFINCS simulation [no vegetation]\n",
    "**Choose between SFINCS CPU or GPU versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edito_process_api import EditoClient, build_s3_from_env\n",
    "client = EditoClient()\n",
    "job_url, final_job, results = client.submit_and_watch(\n",
    "    \"process-playground-sfincs-run-docker-gpu-0.2.3\",\n",
    "    metadata={},\n",
    "    process_inputs={\n",
    "        \"onyxia\": {\"friendlyName\": \"sfincs-gpu\", \"share\": False},\n",
    "        \"resources\": {\n",
    "            \"requests\": {\"cpu\": \"1000m\", \"memory\": \"4Gi\"},\n",
    "            \"limits\":   {\"cpu\": \"4000m\", \"memory\": \"16Gi\", \"nvidia.com/gpu\": \"1\"},\n",
    "        },\n",
    "        \"s3\": build_s3_from_env(),\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import simulation output [no vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from edito_process_api import EditoClient\n",
    "from download_from_s3 import download_nc_files_from_s3\n",
    "\n",
    "client = EditoClient()\n",
    "\n",
    "# 1) wait for completion\n",
    "final_job = client.wait_until_success(job_url, poll_seconds=5, timeout_seconds=7200)\n",
    "\n",
    "# 2) download outputs\n",
    "download_nc_files_from_s3(\n",
    "    files_to_download=[\"sfincs_map.nc\", \"sfincs_his.nc\"],\n",
    "    s3_subfolder=\"SFINCS_OUTPUT\",\n",
    "    local_output_dir=join(sim_dir, \"sim_noveg\"),  # or \"sim_veg\"\n",
    ")\n",
    "print(\"✅ Download complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload model to EDITO storage [vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os.path import join\n",
    "from typing import List\n",
    "\n",
    "# your uploader\n",
    "from upload_model import upload_model_to_s3_bucket\n",
    "\n",
    "# ---- configure per run ----\n",
    "SIM_DIR          = sim_dir                     # assume you already defined this elsewhere\n",
    "NOVEG_DIR        = join(SIM_DIR, \"sim_noveg\")  # where you downloaded model outputs\n",
    "VEG_DIR          = join(SIM_DIR, \"sim_veg\")    # the directory to upload as the next model\n",
    "REQUIRED_FILES   = [\"sfincs_map.nc\", \"sfincs_his.nc\"]\n",
    "S3_TARGET_PREFIX = \"SFINCS_INPUT\"              # destination subfolder\n",
    "\n",
    "def all_present_nonempty(folder: str, names: List[str]) -> bool:\n",
    "    ok = True\n",
    "    for n in names:\n",
    "        p = Path(folder) / n\n",
    "        if not p.exists():\n",
    "            print(f\"❌ missing: {p}\")\n",
    "            ok = False\n",
    "        elif p.stat().st_size == 0:\n",
    "            print(f\"❌ empty file: {p}\")\n",
    "            ok = False\n",
    "        else:\n",
    "            print(f\"✅ found: {p}  ({p.stat().st_size} bytes)\")\n",
    "    return ok\n",
    "\n",
    "# 1) verify sim_noveg was downloaded correctly\n",
    "print(f\"Checking downloads in: {NOVEG_DIR}\")\n",
    "if not all_present_nonempty(NOVEG_DIR, REQUIRED_FILES):\n",
    "    raise RuntimeError(\"Download in sim_noveg is incomplete — aborting upload step.\")\n",
    "\n",
    "# 2) sanity check that sim_veg exists and is not empty (to avoid uploading an empty folder)\n",
    "veg_paths = list(Path(VEG_DIR).glob(\"*\"))\n",
    "if not veg_paths:\n",
    "    raise RuntimeError(f\"'{VEG_DIR}' is empty or missing — nothing to upload.\")\n",
    "\n",
    "# (optional) show what will be uploaded\n",
    "print(f\"Uploading {len(veg_paths)} items from {VEG_DIR} → s3://<your-bucket>/{S3_TARGET_PREFIX}/\")\n",
    "\n",
    "# 3) upload sim_veg ONLY after sim_noveg verified\n",
    "upload_model_to_s3_bucket(VEG_DIR, S3_TARGET_PREFIX)\n",
    "print(\"✅ Upload complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SFINCS simulation [vegetation]\n",
    "**Choose between SFINCS CPU or GPU versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edito_process_api import EditoClient, build_s3_from_env\n",
    "client = EditoClient()\n",
    "job_url, final_job, results = client.submit_and_watch(\n",
    "    \"process-playground-sfincs-run-docker-gpu-0.2.3\",\n",
    "    metadata={},\n",
    "    process_inputs={\n",
    "        \"onyxia\": {\"friendlyName\": \"sfincs-gpu\", \"share\": False},\n",
    "        \"resources\": {\n",
    "            \"requests\": {\"cpu\": \"1000m\", \"memory\": \"4Gi\"},\n",
    "            \"limits\":   {\"cpu\": \"4000m\", \"memory\": \"16Gi\", \"nvidia.com/gpu\": \"1\"},\n",
    "        },\n",
    "        \"s3\": build_s3_from_env(),\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import simulation output [vegetation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- use it (assuming you already have job_url) ----\n",
    "final_job = client.wait_until_success(job_url, poll_seconds=5, timeout_seconds=7200)\n",
    "\n",
    "# proceed: download outputs\n",
    "download_nc_files_from_s3(\n",
    "    files_to_download=[\"sfincs_map.nc\", \"sfincs_his.nc\"],\n",
    "    s3_subfolder=\"SFINCS_OUTPUT\",\n",
    "    local_output_dir=join(sim_dir, \"sim_veg\"),  # or \"sim_veg\"\n",
    ")\n",
    "print(\"✅ Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfincs_utils import load_hmax_noveg, load_h_his\n",
    "from plot_utils import plot_snapshots_every_nth\n",
    "from movie_utils import make_movie_from_pngs\n",
    "\n",
    "# Setup\n",
    "dir_noveg = join(sim_dir, 'sim_noveg')\n",
    "dir_veg = join(sim_dir, 'sim_veg')\n",
    "out_dir = join(sim_dir, 'figs/dif')\n",
    "out_dir_his = join(sim_dir, 'figs')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Load model output\n",
    "hmin = 0.05\n",
    "fs_ticks = 9\n",
    "da_h_dif, da_h_noveg, mod = load_hmax_noveg(dir_noveg, dir_veg, hmin)\n",
    "his_noveg, his_veg = load_h_his(dir_noveg, dir_veg)\n",
    "print(\"✅ Model outputs loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot water level forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import plot_waterlevel_forcing\n",
    "\n",
    "# Plot water level forcing\n",
    "plot_waterlevel_forcing(\n",
    "    input_path=input_dir,\n",
    "    output_path=join(out_dir_his, 'forcing_wl.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot time series difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_utils import plot_observed_h_difference\n",
    "\n",
    "plot_observed_h_difference(\n",
    "    his_noveg=his_noveg,\n",
    "    his_veg=his_veg,\n",
    "    output_path=join(out_dir_his, 'obs_dif.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply GSWO mask\n",
    "gswo = data_cat.get_rasterdataset(join(input_dir, 'gswo.tif'))\n",
    "gswo_mask = gswo.raster.reproject_like(mod.grid, method=\"max\") <= 5\n",
    "da_h_noveg = da_h_noveg.where(gswo_mask).where(da_h_noveg > hmin)\n",
    "da_h_dif = da_h_dif.where(abs(da_h_dif) > hmin / 2)\n",
    "\n",
    "# Only plot every nth timestep\n",
    "plot_snapshots_every_nth(\n",
    "    da_h_noveg=da_h_noveg,\n",
    "    da_h_dif=da_h_dif,\n",
    "    his_noveg=his_noveg,\n",
    "    out_dir=out_dir,\n",
    "    n=20\n",
    ")\n",
    "\n",
    "# Create movie\n",
    "make_movie_from_pngs(out_dir, fps=4, show_first_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload plots to EDITO storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy movie to figs/\n",
    "movie_src = join(sim_dir, 'figs', 'dif', 'output_movie.mp4')\n",
    "movie_dst = join(sim_dir, 'figs', 'output_movie.mp4')\n",
    "shutil.copy(movie_src, movie_dst)\n",
    "\n",
    "#Upload figures and movie\n",
    "upload_model_to_s3_bucket(join(sim_dir, 'figs'), 'SFINCS_OUTPUT', clean_s3=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sfincs_vegetation)",
   "language": "python",
   "name": "sfincs_vegetation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
